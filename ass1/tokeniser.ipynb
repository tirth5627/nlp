{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fc05a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34c7769c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ABBREVIATIONS = {\n",
    "    \"Dr.\", \"Mr.\", \"Mrs.\", \"Ms.\", \"Prof.\", \"Sr.\", \"Jr.\", \"St.\", \"vs.\", \"etc.\", \"e.g.\", \"i.e.\", \"U.S.\", \"U.K.\", \"Ph.D.\", \"B.Sc.\", \"M.Sc.\",\n",
    "    'ડો.', 'ડૉ.', 'પ્રો.', 'શ્રી.', 'સુશ્રી.', 'શ્રીમતી.', 'તા.', 'વગેરે.', 'ઇ.સ.', 'એલ.ટી.', 'વિ.સ.', 'મા.', 'સા.', 'પ્રા.', 'મુ.', 'ના.', \n",
    "    \"શ્રીએ.\", \"મી.\", \"પ્રોફ.\", \"એમ.એ.\", \"બી.એ.\", \"એમ.બી.બી.એસ.\", \"પી.એચ.ડી.\", \"પી.એમ.\", \"એ.કે.\", \"એમ.કે.\"\n",
    "}\n",
    "\n",
    "def gujarati_sentence_tokenizer(text):\n",
    "    sentence_endings = r'([\\.\\?\\!\\।](?!\\d|\\.|[a-zA-Z]+|[\\u0A80-\\u0AFF]))'\n",
    "    parts = re.split(sentence_endings, text)\n",
    "    chunks = []\n",
    "    \n",
    "    for i in range(0, len(parts) - 1, 2):\n",
    "        sentence = parts[i].strip() + parts[i + 1]\n",
    "        chunks.append(sentence)\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(chunks):\n",
    "        current = chunks[i]\n",
    "        if any(current.endswith(abbr) for abbr in ABBREVIATIONS) and i + 1 < len(chunks):\n",
    "            current += \" \" + chunks[i + 1]\n",
    "            i += 1\n",
    "        yield current\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1491e444",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gujarati_word_tokenizer(sentence):\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence.strip())\n",
    "\n",
    "    url_pattern = r'https?://\\S+|www\\.\\S+'\n",
    "    email_pattern = r'\\b[\\w\\.-]+@[\\w\\.-]+\\.\\w+\\b'\n",
    "    date_pattern = r'\\b\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}\\b|\\b\\d{1,2}(?:st|nd|rd|th)?\\s+\\w+\\s+\\d{4}\\b'\n",
    "    number_pattern = r'\\b\\d+(?:[\\.,]\\d+)?\\b'\n",
    "    full_pattern = re.compile(\n",
    "        f'{url_pattern}|{email_pattern}|{date_pattern}|{number_pattern}|[a-zA-Z]+|[\\u0A80-\\u0AFF]+|[^\\w\\s]',\n",
    "        re.UNICODE\n",
    "    )\n",
    "    words = re.findall(full_pattern, sentence)\n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2664abf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\n",
    "    \"ai4bharat/IndicCorpV2\",\n",
    "    split=\"guj_Gujr\",\n",
    "    streaming=True\n",
    ")\n",
    "\n",
    "parquet_file = \"gujarati_rawtext.parquet\"\n",
    "writer = None\n",
    "batch_size = 100000\n",
    "buffer = []\n",
    "cnt=0\n",
    "for i, example in enumerate(dataset):\n",
    "    if(cnt>100):\n",
    "        break\n",
    "    if 'text' in example:\n",
    "        buffer.append({\"text\": example[\"text\"]})\n",
    "    \n",
    "    if len(buffer) >= batch_size:\n",
    "        df = pd.DataFrame(buffer)\n",
    "        table = pa.Table.from_pandas(df)\n",
    "        \n",
    "        if writer is None:\n",
    "            writer = pq.ParquetWriter(parquet_file, table.schema, compression=\"snappy\")\n",
    "        \n",
    "        writer.write_table(table)\n",
    "        buffer.clear()\n",
    "        cnt+=1\n",
    "    \n",
    "if buffer:\n",
    "    df = pd.DataFrame(buffer)\n",
    "    table = pa.Table.from_pandas(df)\n",
    "    if writer is None:\n",
    "        writer = pq.ParquetWriter(parquet_file, table.schema, compression=\"snappy\")\n",
    "    writer.write_table(table)\n",
    "\n",
    "if writer:\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d91be28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_parquet(\"gujarati_rawtext.parquet\", engine=\"pyarrow\")\n",
    "parquet_file = \"gujarati_sentence_tokenized.parquet\"\n",
    "writer = None\n",
    "batch_size = 100000\n",
    "buffer = []\n",
    "\n",
    "for idx, row in df_raw.iterrows():\n",
    "    text = row[\"text\"]\n",
    "    for sent in gujarati_sentence_tokenizer(text):\n",
    "        buffer.append({\n",
    "            \"sentence\": sent\n",
    "        })\n",
    "        if len(buffer) >= batch_size:\n",
    "            df_batch = pd.DataFrame(buffer)\n",
    "            table = pa.Table.from_pandas(df_batch)\n",
    "            if writer is None:\n",
    "                writer = pq.ParquetWriter(parquet_file, table.schema, compression=\"snappy\")\n",
    "            writer.write_table(table)\n",
    "            buffer.clear()\n",
    "\n",
    "if buffer:\n",
    "    df_batch = pd.DataFrame(buffer)\n",
    "    table = pa.Table.from_pandas(df_batch)\n",
    "    if writer is None:\n",
    "        writer = pq.ParquetWriter(parquet_file, table.schema, compression=\"snappy\")\n",
    "    writer.write_table(table)\n",
    "\n",
    "if writer:\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797f9e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_parquet(\"gujarati_rawtext.parquet\", engine=\"pyarrow\")\n",
    "parquet_file = \"gujarati_word_tokenized.parquet\"\n",
    "writer = None\n",
    "batch_size = 100000\n",
    "buffer = []\n",
    "\n",
    "for idx, row in df_raw.iterrows():\n",
    "    text = row[\"text\"]\n",
    "    for sent in gujarati_word_tokenizer(text):\n",
    "        buffer.append({\n",
    "            \"sentence\": sent\n",
    "        })\n",
    "        if len(buffer) >= batch_size:\n",
    "            df_batch = pd.DataFrame(buffer)\n",
    "            table = pa.Table.from_pandas(df_batch)\n",
    "            if writer is None:\n",
    "                writer = pq.ParquetWriter(parquet_file, table.schema, compression=\"snappy\")\n",
    "            writer.write_table(table)\n",
    "            buffer.clear()\n",
    "\n",
    "if buffer:\n",
    "    df_batch = pd.DataFrame(buffer)\n",
    "    table = pa.Table.from_pandas(df_batch)\n",
    "    if writer is None:\n",
    "        writer = pq.ParquetWriter(parquet_file, table.schema, compression=\"snappy\")\n",
    "    writer.write_table(table)\n",
    "\n",
    "if writer:\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dcd3087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Total Sentences': 12118231, 'Total Words': 237091043, 'Total Characters': 1044270277, 'Average Sentence Length': 19.564822868948447, 'Average Word Length': 4.404511717467116, 'Type/Token Ratio': 0.01124690315694465}\n"
     ]
    }
   ],
   "source": [
    "df_sentence= pd.read_parquet(\"gujarati_sentence_tokenized.parquet\", engine=\"pyarrow\")\n",
    "df_word=pd.read_parquet(\"gujarati_word_tokenized.parquet\", engine=\"pyarrow\")\n",
    "total_sentences = len(df_sentence)\n",
    "total_words = len(df_word)\n",
    "total_chars =0\n",
    "for i in df_word['sentence']:\n",
    "    total_chars+=len(i)\n",
    "avg_sentence_len = total_words / total_sentences\n",
    "avg_word_len = total_chars / total_words\n",
    "unique_tokens = len(set(token for token in df_word['sentence']))\n",
    "ttr = unique_tokens / total_words\n",
    "stats = {\n",
    "    \"Total Sentences\": total_sentences,\n",
    "    \"Total Words\": total_words,\n",
    "    \"Total Characters\": total_chars,\n",
    "    \"Average Sentence Length\": avg_sentence_len,\n",
    "    \"Average Word Length\": avg_word_len,\n",
    "    \"Type/Token Ratio\": ttr\n",
    "}\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d86443a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>આ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>વીડિયો</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>જુઓ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ઊંઝા</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237091038</th>\n",
       "      <td>છોડીને</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237091039</th>\n",
       "      <td>ભાગી</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237091040</th>\n",
       "      <td>રહ્યા</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237091041</th>\n",
       "      <td>છે</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237091042</th>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>237091043 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          sentence\n",
       "0                આ\n",
       "1           વીડિયો\n",
       "2              જુઓ\n",
       "3                :\n",
       "4             ઊંઝા\n",
       "...            ...\n",
       "237091038   છોડીને\n",
       "237091039     ભાગી\n",
       "237091040    રહ્યા\n",
       "237091041       છે\n",
       "237091042        .\n",
       "\n",
       "[237091043 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_word"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
