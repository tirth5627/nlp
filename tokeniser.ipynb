{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc05a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "ABBREVIATIONS = {\n",
    "    \"Dr.\", \"Mr.\", \"Mrs.\", \"Ms.\", \"Prof.\", \"Sr.\", \"Jr.\", \"St.\", \"vs.\", \"etc.\", \"e.g.\", \"i.e.\", \"U.S.\", \"U.K.\", \"Ph.D.\", \"B.Sc.\", \"M.Sc.\",\n",
    "\n",
    "    'ડો.', 'ડૉ.', 'પ્રો.', 'શ્રી.', 'સુશ્રી.', 'શ્રીમતી.', 'તા.', 'વગેરે.', 'ઇ.સ.', 'વિ.સ.', 'મા.', 'સા.', 'પ્રા.', 'મુ.', 'ના.',\"શ્રીએ.\", \"મી.\", \"પ્રોફ.\", \"એમ.એ.\", \"બી.એ.\", \"એમ.બી.બી.એસ.\", \"પી.એચ.ડી.\", \"પી.એમ.\", \"એ.કે.\", \"એમ.કે.\"\n",
    "\n",
    "}\n",
    "def gujarati_sentence_tokenizer(text):\n",
    "    sentence_endings = r'([\\.\\?\\!\\।](?!\\d))'\n",
    "    parts = re.split(sentence_endings, text)\n",
    "    chunks = []\n",
    "    for i in range(0, len(parts) - 1, 2):\n",
    "     sentence = parts[i].strip() + parts[i + 1]\n",
    "     chunks.append(sentence)\n",
    "    sentences = []\n",
    "    i = 0\n",
    "    while i < len(chunks):\n",
    "        current = chunks[i]\n",
    "        if any(current.endswith(abbr) for abbr in ABBREVIATIONS) and i + 1 < len(chunks):\n",
    "            current += \" \" + chunks[i + 1]\n",
    "            i += 1\n",
    "        sentences.append(current)\n",
    "        i += 1\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1491e444",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def gujarati_word_tokenizer(sentence):\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence.strip())\n",
    "\n",
    "    url_pattern = r'https?://\\S+'\n",
    "    email_pattern = r'\\b[\\w\\.-]+@[\\w\\.-]+\\.\\w+\\b'\n",
    "    date_pattern = r'\\b\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}\\b|\\b\\d{1,2}(?:st|nd|rd|th)?\\s+\\w+\\s+\\d{4}\\b'\n",
    "    number_pattern = r'\\b\\d+(?:[\\.,]\\d+)?\\b'\n",
    "    full_pattern = re.compile(\n",
    "        f'{url_pattern}|{email_pattern}|{date_pattern}|{number_pattern}|[a-zA-Z]+|[\\u0A80-\\u0AFF]+|[^\\w\\s]',\n",
    "        re.UNICODE\n",
    "    )\n",
    "\n",
    "    words = re.findall(full_pattern, sentence)\n",
    "    return words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d91be28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\n",
    "    \"ai4bharat/IndicCorpV2\",\n",
    "    split=\"guj_Gujr\",\n",
    "    streaming=True\n",
    ")\n",
    "\n",
    "data=\"\"\n",
    "for i, example in enumerate(dataset):\n",
    "    if i >= 10000:\n",
    "        break\n",
    "    if 'text' in example:\n",
    "        data += example['text']\n",
    "sentence_token=gujarati_sentence_tokenizer(data)\n",
    "word_token=gujarati_word_tokenizer(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35521382",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word_token)\n",
    "print(sentence_token)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
